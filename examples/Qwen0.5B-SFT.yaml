# Model arguments
seed: 42
model_name_or_path: /data4/wedoctor/model/qwen2-0.5B-Instruct
torch_dtype: auto

# Data training arguments

dataset_name: /data4/wedoctor/yangqinglin/wedoctor_r1/data/wedoctor_20250312.json

# training arguments
bf16: true
num_train_epochs: 1
gradient_accumulation_steps: 4
per_device_train_batch_size: 4
gradient_checkpointing: true
learning_rate: 2.0e-05
packing: true
max_length: 4096
logging_steps: 10
logging_strategy: steps
lr_scheduler_type: cosine
output_dir: output/qwen2-0.5B-Instruct-sft
overwrite_output_dir: true
warmup_ratio: 0.1
save_strategy: steps
save_steps: 500

# eval arguments
# do_eval: no
# per_device_eval_batch_size: 4
# eval_strategy: no
# eval_steps: 10